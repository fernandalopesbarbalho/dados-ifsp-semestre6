# -*- coding: utf-8 -*-
"""Aula 120.B Modelagem de dados.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qjYO4poF8V46I4-B1GGF9oXFWR7VayJU

## Introdução

Este notebook aborda os modelos múltiplos de classificação, também conhecidos como métodos *ensemble*. Esses modelos fazem a combinação de classificadores para obterem melhor desempenho na tarefa de classificação. Mais especificamente, será explorado o método Floresta Aleatória (RF -- *Random Forest*) [1] que faz a combinação de árvores de decisão. Será comparado o resultado desse método com o resultado de uma árvore de decisão [2].

Os procedimentos serão realizados com a base de dados Seeds [1] que está na pasta [datasets](https://drive.google.com/file/d/1k4avL1CCtfpteBqurWhWAUDHjP8bbnw_/view?usp=drive_link). Ela contém três variedades de trigo: Kama, Rosa e Canadense. Essas três variedades são representadas pelos seguintes atributos: área, perímetro, compacidade, comprimento do grão, largura do grão, coeficiente de assimetria e comprimento do sulco do grão [1].

Ao final deste notebook, é esperado que o aluno tenha assimilado os principais conceitos relacionados aos modelos múltiplos de classificação por meio da observação dos resultados obtidos pelo método RF e da sua comparação com os resultados obtidos com uma árvore de decisão.

---
## Recursos necessários

Para este notebook, deve ser utilizado o `Python 3.5` ou superior com as seguintes bibliotecas externas, que deverão ser instaladas:

* [`matplotlib`](https://matplotlib.org/stable/index.html) (versão 3.1.3 ou superior): construção e exibição de gráficos variados
* [`seaborn`](https://seaborn.pydata.org/) (versão 0.10.0 ou superior): construção e exibição de gráficos variados
* [`numpy`](https://numpy.org) (versão 1.16.2 ou superior): manipulação de dados em formato de vetores e matrizes
* [`pandas`](https://pandas.pydata.org/pandas-docs/stable/index.html) (versão 0.24.1 ou superior): manipulação de dados em formato de tabelas
* [`graphviz`](https://pypi.org/project/graphviz/) (versão  0.14.1 ou superior): exibição da árvore de decisão
* [`pydotplus`](https://pandas.pydata.org/pandas-docs/stable/index.html) (versão 2.0.2 ou superior): exibição da árvore de decisão
* [`scikit-learn`](https://scikit-learn.org/stable/) (versão 0.22.1 ou superior): conjunto de métodos e modelos úteis para Aprendizado de Máquina e Inteligência Artificial

---
## Métodos de Ensemble

Importação das bibliotecas que serão usadas ao longo deste notebook.
"""

# Commented out IPython magic to ensure Python compatibility.
# -*- coding: utf-8 -*-

# %matplotlib inline

from google.colab import drive

import numpy as np # biblioteca usada para trabalhar com vetores e matrizes
import pandas as pd # biblioteca usada para trabalhar com dataframes e análise de dados
import sklearn as skl # sckit-learn
import time # biblioteca usada para calcular o tempo de execucao
import re # biblioteca para expressões regulares

# importa alguns pacotes do sckit-learn
from sklearn import model_selection
from sklearn import linear_model # necessário para usar regressão logística
from sklearn import ensemble # necessário para usar os metodos ensemble
from sklearn import naive_bayes # necessário para usar o metodo naive Bayes
from sklearn import tree # necessário para usar arvores de decisao
from sklearn import svm # necessário para usar o metodo SVM
from sklearn import neighbors # necessário para usar o metodo KNN
from sklearn import model_selection # necessário para fazer validação cruzada
from sklearn import metrics # necessário para obter o desempenho da classificação

# bibliotecas para geração de gráficos
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from IPython.display import Image
import seaborn as sns

import pydotplus # usada para plotar a arvore de decisao

print('Bibliotecas carregadas com sucesso')

# @title Função auxiliar para consolidar as medidas de desempenho

def relatorioDesempenho(Y_test, Y_pred, classes=['Canadense' 'Kama' 'Rosa'], imprimeRelatorio=True):
  """
  Funcao usada calcular as medidas de desempenho da classificação.

  Parametros
  ----------

  classes: classes do problema

  imprimeRelatorio: variavel booleana que indica se o relatorio de desempenho
                    deve ser impresso ou nao.

  Retorno
  -------
  resultados: variavel do tipo dicionario (dictionary). As chaves
              desse dicionario serao os nomes das medidas de desempenho; os valores
              para cada chave serao as medidas de desempenho calculadas na funcao.

              Mais especificamente, o dicionario devera conter as seguintes chaves:

               - acuracia: valor entre 0 e 1
               - revocacao: um vetor contendo a revocacao obtida em relacao a cada classe
                            do problema
               - precisao: um vetor contendo a precisao obtida em relacao a cada classe
                            do problema
               - fmedida: um vetor contendo a F-medida obtida em relacao a cada classe
                            do problema
               - revocacao_macroAverage: valor entre 0 e 1
               - precisao_macroAverage: valor entre 0 e 1
               - fmedida_macroAverage: valor entre 0 e 1
               - revocacao_microAverage: valor entre 0 e 1
               - precisao_microAverage: valor entre 0 e 1
               - fmedida_microAverage: valor entre 0 e 1
  """

  # obtém a quantidade de classes
  nClasses = len(classes)

  #obtem a acuracia
  acuracia = metrics.accuracy_score(Y_test, Y_pred)

  # inicializa as medidas de desempenho
  revocacao = np.zeros( len(classes) )
  precisao = np.zeros( len(classes) )
  fmedida = np.zeros( len(classes) )

  # calcula a medida de desempenho para cada classe individualmente
  for i in range( len(classes) ):

      #transforma o problema multiclasse em binário, apenas para calcular o desempenho individual da classe i
      auxY_test = np.zeros( len(Y_test) ) # inicializa o vetor de classes binárias com 0
      auxY_pred = np.zeros( len(Y_pred) ) # inicializa o vetor de classes binárias com 0
      auxY_test[Y_test==classes[i]] = 1 # onde a classe for igual a classe[i], recebe valor 1
      auxY_pred[Y_pred==classes[i]] = 1 # onde a classe for igual a classe[i], recebe valor 1

      revocacao[i] = metrics.recall_score(auxY_test, auxY_pred, pos_label=1) # recall
      precisao[i] = metrics.precision_score(auxY_test, auxY_pred, pos_label=1) # precision
      fmedida[i] = metrics.f1_score(auxY_test, auxY_pred, pos_label=1) # precision


  revocacao_microAverage =  metrics.recall_score(Y_test, Y_pred, average='micro') # sensitividade ou recall
  precisao_microAverage = metrics.precision_score(Y_test, Y_pred, average='micro')
  fmedida_microAverage = metrics.f1_score(Y_test, Y_pred, average='micro')

  revocacao_macroAverage =  metrics.recall_score(Y_test, Y_pred, average='macro') # sensitividade ou recall
  precisao_macroAverage = metrics.precision_score(Y_test, Y_pred, average='macro')
  fmedida_macroAverage = metrics.f1_score(Y_test, Y_pred, average='macro')


  # imprimindo os resultados para cada classe
  if imprimeRelatorio:

      print('\n\tRevocacao   Precisao   F-medida   Classe')
      for i in range(nClasses):
        print('\t%1.3f       %1.3f      %1.3f      %s' % (revocacao[i], precisao[i], fmedida[i],classes[i] ) )

      print('\t------------------------------------------------');

      #imprime as médias
      print('\t%1.3f       %1.3f      %1.3f      Média macro' % (revocacao_macroAverage, precisao_macroAverage, fmedida_macroAverage) )
      print('\t%1.3f       %1.3f      %1.3f      Média micro\n' % (revocacao_microAverage, precisao_microAverage, fmedida_microAverage) )

      print('\tAcuracia: %1.3f' %acuracia)

  # guarda os resultados em uma estrutura tipo dicionario
  resultados = {'revocacao': revocacao, 'acuracia': acuracia, 'precisao':precisao, 'fmedida':fmedida}
  resultados.update({'revocacao_macroAverage':revocacao_macroAverage, 'precisao_macroAverage':precisao_macroAverage, 'fmedida_macroAverage':fmedida_macroAverage})
  resultados.update({'revocacao_microAverage':revocacao_microAverage, 'precisao_microAverage':precisao_microAverage, 'fmedida_microAverage':fmedida_microAverage})

  return resultados

# @title Função auxiliar para mostrar a árvore de decisão selecionada pelo modelo

def plota_arvore(classifier, df_dataset, classes=['Canadense' 'Kama' 'Rosa']):

    '''
    Funcao usada calcular as medidas de desempenho da classificação.

    Parametros
    ----------
    classifier: classificador que foi treinado
    df_dataset: leitura do arquivo csv com os dados
    classes: classes do problema
    '''

    # define o plote
    dot_data = tree.export_graphviz(classifier, feature_names=df_dataset.columns[0:-1],
                                    class_names=classes,rounded=True, proportion=False,
                                    precision=2, filled=False)

    graph = pydotplus.graph_from_dot_data(dot_data).to_string()

    # modifica as informacoes dos nos
    graph = re.sub('(\\\\ngini = [0-9].[0-9]+)(\\\\nsamples = [0-9]+)(\\\\nvalue = \[[0-9]+, [0-9]+, [0-9]+\])', '', graph)
    graph = re.sub('(gini = [0-9].[0-9]+)(\\\\nsamples = [0-9]+)(\\\\nvalue = \[[0-9]+, [0-9]+, [0-9]+\])\\\\n', '', graph)

    # desenha o grafo
    graph = pydotplus.graph_from_dot_data(graph)

    # exibe o grafo
    display(Image(graph.create_png()))

"""Vamos carregar os dados do arquivo e visualizar as suas primeiras amostras. É importante notar que o arquivo original da base de dados não possui título para suas colunas e, por isso, na função `read_csv` do pandas definiremos o parâmetro `header = None`.

# Montar o Google Drive
"""

drive.mount('/content/drive', force_remount=True)

"""# Ler o arquivo

Utilizaremos o conjunto de dados de [diabetes](https://drive.google.com/file/d/1k4avL1CCtfpteBqurWhWAUDHjP8bbnw_/view?usp=drive_link) para a indução de modelos.
"""

# @title Neste parágrafo, realize a leitura do arquivo CSV

file_path = '/content/drive/MyDrive/Colab Notebooks/seeds_dataset.csv';

df_dataset = pd.read_csv(file_path, sep="\t", header=None);

# @title Neste parágrafo, imprima 10 linhas do dataframe.

print(df_dataset.head(10))

"""- Para facilitar a visualização, altere o nome das colunas da base de dados com os nomes dos atributos: **['area', 'perimetro', 'compacidade', 'compr.Grao', 'larg.Grao', 'coef.Assimetria', 'Compr.SulcoGrao', 'classe']**
- Substituir o valor das classes pelo nome da variedade de trigo que ela representa: **1 (Kama), 2 (Rosa), 3 (Canadense)**.
- Veja a figura exemplo:
- ![dataset.PNG](data:image/png;base64,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)
"""

# @title Neste parágrafo, alterar o nome das colunas e substituir o valor das classes. Depois, imprimir 10 linhas do dataset resultante.

colunas = ['area', 'perimetro', 'compacidade', 'compr.Grao', 'larg.Grao', 'coef.Assimetria', 'Compr.SulcoGrao', 'classe']
df_dataset.columns = colunas

mapeamento_classes = {1: 'Kama', 2: 'Rosa', 3: 'Canadense'}
df_dataset['classe'] = df_dataset['classe'].map(mapeamento_classes)

print(df_dataset.head(10))

"""Crie os gráficos de dispersão para cada combinação de atributos."""

# @title Neste prágrafo, crie os gráficos de dispersão para cada combinação de atributos

print("Gráficos de dispersão (Pairplot):")
sns.pairplot(df_dataset, hue='classe')
plt.show()

# @title Neste parágrafo, imprima as principais estatísticas sobre os atributos preditivos da base de dados: média, desvio padrão, quartis.

print(df_dataset.describe())

# @title Neste parágrafo, conte quantos exemplos há em cada classe e crie um gráfico para mostrar o resultado

contagem_classes = df_dataset['classe'].value_counts()
print("Contagem de classes:")
print(contagem_classes)

plt.figure(figsize=(8, 5))
sns.countplot(x='classe', data=df_dataset, order=contagem_classes.index)
plt.title('Distribuição das Classes')
plt.xlabel('Variedade de Trigo')
plt.ylabel('Contagem')
plt.show()

# @title Neste parágrafo, separe os atributos preditivos em uma matriz X e o atributo alvo em uma vetor Y

X = df_dataset.drop('classe', axis=1)
Y = df_dataset['classe']

print("Dimensões de X (atributos):", X.shape)
print("Dimensões de Y (alvo):", Y.shape)

"""- Divida os dados de treino e teste de forma estratificada.
- Utilize a validação *holdout* estratificada (30% para teste).
"""

# @title Neste parágrafo, realize a divisão dos dados entre treino e teste. Utilize a técnica Houdout estratificado (30%)

X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.3, stratify=Y, random_state=42)

print("Dimensões de X_train:", X_train.shape)
print("Dimensões de X_test:", X_test.shape)
print("Dimensões de Y_train:", Y_train.shape)
print("Dimensões de Y_test:", Y_test.shape)

"""- Existem diversos métodos múltiplos de classificação, mas neste exercício iremos usar a **Floresta Aleatória**.
- Um dos parâmetros que devemos setar para esse método é o **n_estimators** que refere-se à quantidade de Árvores de Decisão que ele irá combinar.
- Como esse parâmetro pode influenciar bastante nos resultados, iremos fazer a escolha do seu valor usando uma busca em grade.
- Os valores que iremos testar, começam em 10 e vão até 200, variando de 20 em 20.
"""

# @title Neste parágrafo, inicialize o classificador Floresta Aleatória com os parâmetros descritos acima.

rf_classificador = ensemble.RandomForestClassifier(random_state=42)

parametros_grid = {
    'n_estimators': range(10, 201, 20)
}

grid_search_rf = model_selection.GridSearchCV(
    estimator=rf_classificador,
    param_grid=parametros_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

print("GridSearchCV para Random Forest inicializado.")
print(f"Valores de 'n_estimators' a serem testados: {list(parametros_grid['n_estimators'])}")

"""- Treinar o método de classicação na partição de treinamento e testar na partição de teste.
- Para imprimir o relatório de desempenho, utilize a função auxiliar (`relatorioDesempenho()`) que se encontra no início do *Notebook*.
"""

# @title Neste parágrafo, treine o modelo Random Forest e imprima o relatório de desempenho

print("Iniciando o treinamento do GridSearchCV:")
start_time = time.time()
grid_search_rf.fit(X_train, Y_train)
end_time = time.time()
print(f"Treinamento concluído em {end_time - start_time:.2f} segundos.")

Y_pred_rf = grid_search_rf.predict(X_test)

classes = np.unique(Y)

print("\n--- Relatório de Desempenho (Random Forest com GridSearchCV) ---")
resultados_rf = relatorioDesempenho(Y_test, Y_pred_rf, classes=classes, imprimeRelatorio=True)

"""Imprima os parâmetros obtidos pela busca em grade."""

# @title Neste parágrafo, imprima os parâmetros obtidos pela busca em grade

print("Melhores parâmetros (melhor 'n_estimators') encontrados pelo GridSearchCV:")
print(grid_search_rf.best_params_)

print("\nMelhor score (acurácia média) durante a validação cruzada (CV):")
print(f"{grid_search_rf.best_score_:.4f}")

"""- Utilize a função `plota_arvore()`, disponível no início do *Notebook*,  que recebe um classificador como entrada e imprime a árvore de decisão gerada.
- Utilize essa função para imprimir a primeira árvore de decisão da melhor Floresta aleatória retornada na busca em grade.
"""

# @title Neste parágrafo, imprima a PRIMEIRA árvore de decisão da melhor Floresta aleatória retornada na busca em grade.

melhor_rf = grid_search_rf.best_estimator_

classes = np.unique(Y)

print("--- Plotando a Árvore 1 da Melhor Floresta Aleatória ---")
plota_arvore(melhor_rf.estimators_[0], df_dataset, classes=classes)

"""Vamos imprimir a segunda árvore de decisão da melhor Floresta aleatória retornada na busca em grade."""

# @title Neste parágrafo, imprima a SEGUNDA árvore de decisão da melhor Floresta aleatória retornada na busca em grade.

print("--- Plotando a Árvore 2 da Melhor Floresta Aleatória ---")
plota_arvore(melhor_rf.estimators_[1], df_dataset, classes=classes)

"""- Agora, faça o treino e teste de uma árvore de decisão simples para comparar com o resultado obtido pela floresta aleatória.
- Como o método Árvore de decisão não possui nenhum parâmetro muito sensível, não faça ajuste fino de parâmetros.
- Para imprimir o relatório de desempenho, utilize a função auxiliar (relatorioDesempenho()) que se encontra no início do Notebook.
"""

# @title Neste parágrafo, treine, teste e imprima o relatório de desempenho de uma árvore de decisão simples

dt_classificador = tree.DecisionTreeClassifier(random_state=42)

print("Treinando a Árvore de Decisão Simples:")
dt_classificador.fit(X_train, Y_train)
print("Treinamento concluído.")

Y_pred_dt = dt_classificador.predict(X_test)

classes = np.unique(Y)
print("\n--- Relatório de Desempenho (Árvore de Decisão Simples) ---")
resultados_dt = relatorioDesempenho(Y_test, Y_pred_dt, classes=classes, imprimeRelatorio=True)

"""Utilize a função `plota_arvore()` e imprima a árvore de decisão gerada."""

# @title Neste parágrafo, imprima a árvore de decisão gerada

classes = np.unique(Y)

print("--- Plotando a Árvore de Decisão Simples ---")
plota_arvore(dt_classificador, df_dataset, classes=classes)

"""- Compare os resultados da Árvore de decisão com a Floresta aleatória.
- Crie um gráfico de barras para a comparação
"""

# @title Neste parágrafo, crie o gráfico de comparação

dados_comparacao = {
    'Modelo': ['Random Forest', 'Árvore de Decisão'],
    'Acurácia': [resultados_rf['acuracia'], resultados_dt['acuracia']],
    'F-medida (Macro)': [resultados_rf['fmedida_macroAverage'], resultados_dt['fmedida_macroAverage']],
    'Precisão (Macro)': [resultados_rf['precisao_macroAverage'], resultados_dt['precisao_macroAverage']],
    'Revocação (Macro)': [resultados_rf['revocacao_macroAverage'], resultados_dt['revocacao_macroAverage']]
}

df_comparacao = pd.DataFrame(dados_comparacao)

df_melted = df_comparacao.melt('Modelo', var_name='Métrica', value_name='Valor')

plt.figure(figsize=(14, 7))
sns.barplot(x='Métrica', y='Valor', hue='Modelo', data=df_melted, palette='viridis')
plt.title('Comparação de Desempenho: Random Forest vs. Árvore de Decisão')
plt.ylabel('Score')
plt.xlabel('Métrica de Desempenho')
plt.ylim(0, 1.1)
plt.legend(loc='best')
plt.show()

"""Pelos gráficos mostrados acima, é possível observar que o método Floresta aleatória obteve os melhores resultados. Porém, pelo fato de ter feito a combinação de várias árvores de decisão, seu custo computacional é bem superior ao custo de gerar uma única árvore.

---
## Conclusão

Neste notebook, foram abordados os modelos múltiplos de classificação. Foi realizada uma comparação entre o desempenho de uma árvore de decisão e do método Floresta aleatória que faz a combinação de várias árvores de decisão. Foi mostrado que o método de Floresta Aleatória pode obter melhores resultados, porém ao custo de um maior consumo de recursos computacionais.

---
## Referências

[1] M. Charytanowicz, J. Niewczas, P. Kulczycki, P.A. Kowalski, S. Lukasik, S. Zak. A Complete Gradient Clustering Algorithm for Features Analysis of X-ray Images. Information Technologies in Biomedicine, Ewa Pietka, Jacek Kawa (eds.), Springer-Verlag, Berlin-Heidelberg, 2010, pp. 15-24. DOI: [10.1007/978-3-642-13105-9_2](http://dx.doi.org/10.1007/978-3-642-13105-9_2).

[2] L. Breiman, J. Friedman, C. J. Stone, R. A. Olshen, Classification and Regression Trees, CRC Press, Boca Raton, FL, USA, 1984.

[3] R. A. Fisher. The use of multiple measurements in taxonomic problems. Annual Eugenics, 7, Part II, 179-188 (1936). DOI: [10.1111/j.1469-1809.1936.tb02137.x](http://dx.doi.org/10.1111/j.1469-1809.1936.tb02137.x).

---
"""