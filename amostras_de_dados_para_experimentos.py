# -*- coding: utf-8 -*-
"""Aula 110. Amostras de Dados para Experimentos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10fpDAvzsbP4Z7op6lMtkWoIDevaSaXzo

# Importação de bibliotecas
"""

from google.colab import drive

import pandas as pd

# Importando o método hold-out
from sklearn.model_selection import train_test_split

# Importando o método StratifiedKFold
from sklearn.model_selection import StratifiedKFold

# Importando o método deixe-um-de-fora
from sklearn.model_selection import LeaveOneOut

# Importando o método ShuffleSplit
from sklearn.model_selection import ShuffleSplit

# Importando o método resample
from sklearn.utils import resample

# Importando o método Counter para contagem dos exemplos das classes
from collections import Counter

# Importando o método RUS
from imblearn.under_sampling import RandomUnderSampler

# Importando o método ROS
from imblearn.over_sampling import RandomOverSampler

# Importando o método SMOTE
from imblearn.over_sampling import SMOTE

"""# Montar o Google Drive"""

drive.mount('/content/drive', force_remount=True)

"""# Ler o arquivo

Utilizaremos o conjunto de dados de [diabetes](https://drive.google.com/file/d/1yN2ACdmyNhxrIGw_Tjb3_jZZ8p047LX1/view?usp=sharing) para esta Avaliação contínua, que trata das técnicas de reamostragem.
"""

file_path = '/content/drive/MyDrive/Colab Notebooks/diabetes.csv'

df = pd.read_csv(file_path);

df

"""# Procedimentos para Reamostragem de Dados

## técnica *hold-out*

- Utilize a técnica ***hold-out*** com 30% para a classe de teste.
- Mantenha a proporção das classes alvo.
"""

# @title Utilize este parágrafo para separar os dados em atributos preditivos (X) e atributo alvo (y)

X = df.drop('Outcome', axis=1)
y = df['Outcome']

# @title Utilize este parágrafo para aplicar a técnica para hold-out (30% para teste)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=42)

# @title Utilize este parágrafo para mostrar a quantidade de exemplos em cada classe da amostra de treinamento e teste

print("Distribuição das classes no conjunto de Treinamento:")
print(Counter(y_train))
print("\nDistribuição das classes no conjunto de Teste:")
print(Counter(y_test))

"""## Técnica Validação cruzada com *k* partições (*k-fold cross-validation*)

- Divida o *dataset* em 10 partes
- Embaralhe os exemplos
- Garanta que o embaralhamento seja reprodutível
"""

# @title Utilize este parágrafo para separar os dados em atributos preditivos (X) e atributo alvo (y)

X = df.drop('Outcome', axis=1)
y = df['Outcome']

# @title Utilize esta parágrafo para inicializar o método

skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

# @title Crie uma estrutura de repetição para mostrar o shape dos conjuntos de treino e teste criados

fold = 1
for train_index, test_index in skf.split(X, y):
    print(f"Fold {fold}:")
    print(f"  Train shape: {X.iloc[train_index].shape}")
    print(f"  Test shape:  {X.iloc[test_index].shape}")
    fold += 1

"""## Técnica deixe-um-de-fora (*leave-one-out*)"""

# @title Utilize este parágrafo para separar os dados em atributos preditivos (X) e atributo alvo (y)

X = df.drop('Outcome', axis=1)
y = df['Outcome']

# @title Utilize este parágrafo para inicializar o método do deixe-um-de-fora

loo = LeaveOneOut()

# @title Crie uma estrutura de repetição para mostrar o shape dos conjuntos de treino e teste criados

print(f"Total de exemplos: {X.shape[0]}. Serão criadas {loo.get_n_splits(X)} iterações.")
print("Mostrando os 5 primeiros folds como exemplo:")

fold = 1
for train_index, test_index in loo.split(X):
    if fold > 5:
        break
    print(f"Fold {fold}:")
    print(f"  Train shape: {X.iloc[train_index].shape}")
    print(f"  Test shape:  {X.iloc[test_index].shape}")
    fold += 1

"""## Técnica *bootstrap* (ou *bootstraping*)

### Estratégia automática

- Quantidade de vezes que a amostragem será feita: 1000
- Tamanho do teste: 0.25
- Semente do random_state: 3
"""

# @title Utilize este parágrafo para separar os dados em atributos preditivos (X) e atributo alvo (y)

X = df.drop('Outcome', axis=1)
y = df['Outcome']

# @title Utilize este parágrafo para inicializar o método bootstrap com a definição da quantidade de vezes que a amostragem será feita, o tamanho do teste e a semente do random_state

bs = ShuffleSplit(n_splits=1000, test_size=0.25, random_state=3)

# @title Crie uma estrutura de repetição para mostrar o shape dos conjuntos de treino e teste criados

print(f"Serão feitas {bs.get_n_splits(X)} amostragens.")
print("Mostrando os 5 primeiros folds como exemplo:")

fold = 1
for train_index, test_index in bs.split(X):
    if fold > 5:
        break
    print(f"Fold {fold}:")
    print(f"  Train shape: {X.iloc[train_index].shape}")
    print(f"  Test shape:  {X.iloc[test_index].shape}")
    fold += 1

"""# Conjuntos de Dados Desbalanceados"""

# @title Utilize este parágrafo para separar os dados em atributos preditivos (X) e atributo alvo (y)

X = df.drop('Outcome', axis=1)
y = df['Outcome']

# @title Utilize este parágrafo para verificar se o conjunto de dados é desbalanceado

print("Distribuição das classes no conjunto de dados completo:")
print(Counter(y))
print("\nProporção das classes:")
print(y.value_counts(normalize=True))

"""## subamostragem aleatória (RUS, *random undersampling*)"""

# @title Utilize este parágrafo para separar os dados em atributos preditivos (X) e atributo alvo (y)

X = df.drop('Outcome', axis=1)
y = df['Outcome']

# @title Utilize este parágrafo para dividir os dados em treinamento e teste com hold-out (30% para teste), semente igual a 12 e mantenha a proporção das classes

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=12)

print("Distribuição original (Treinamento):", Counter(y_train))

# @title Utilize este parágrafo para aplicar o RUS

rus = RandomUnderSampler(random_state=0)
X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)

# @title Utilize este parágrafo para mostrar se as classes foram balanceadas de acordo com o RUS

print("Distribuição após RUS (Treinamento):", Counter(y_train_rus))

"""## superamostragem aleatória (ROS, *random oversampling*)"""

# @title Utilize este parágrafo para separar os dados em atributos preditivos (X) e atributo alvo (y)

X = df.drop('Outcome', axis=1)
y = df['Outcome']

# @title Utilize este parágrafo para dividir os dados em treinamento e teste com hold-out (30% para teste), semente igual a 12 e mantenha a proporção das classes

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=12)

print("Distribuição original (Treinamento):", Counter(y_train))

# @title Utilize este parágrafo para aplicar o ROS

ros = RandomOverSampler(random_state=0)
X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)

# @title Utilize este parágrafo para mostrar se as classes foram balanceadas de acordo com o ROS

print("Distribuição após ROS (Treinamento):", Counter(y_train_ros))

"""## *Synthetic Minority Oversampling TEchnique* (SMOTE)

- Utilize a técnica SMOTE para criar exemplos sintéticos para a classe minoritária
"""

# @title Utilize este parágrafo para separar os dados em atributos preditivos (X) e atributo alvo (y)

X = df.drop('Outcome', axis=1)
y = df['Outcome']

# @title Utilize este parágrafo para dividir os dados em treinamento e teste com hold-out (30% para teste), semente igual a 12 e mantenha a proporção das classes

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=12)

print("Distribuição original (Treinamento):", Counter(y_train))

# @title Utilize este parágrafo para aplicar Synthetic Minority Oversampling TEchnique (SMOTE)

smote = SMOTE(random_state=0)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# @title Utilize este parágrafo para mostrar se as classes foram balanceadas de acordo com o SMOTE

print("Distribuição após SMOTE (Treinamento):", Counter(y_train_smote))