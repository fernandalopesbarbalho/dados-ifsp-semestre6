# -*- coding: utf-8 -*-
"""Aula 130. Avaliação, Ajuste e Seleção de Modelos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sogEtxNR2nYVd_sQzv20qr3bCuyx8HrN

# Instalação de bibliotecas
"""

!pip install -U scikit-learn

"""# Importação de bibliotecas"""

from google.colab import drive

import pandas as pd

import numpy as np

from sklearn.datasets import fetch_california_housing

from sklearn.model_selection import train_test_split

# Importando o regressor baseado em Árvore de Decisão
from sklearn.tree import DecisionTreeRegressor

# Importando as métricas de avaliação para regressão
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Importando o classificador baseado em Árvore de Decisão
from sklearn.tree import DecisionTreeClassifier

# Importando as métricas de avaliação para classificação
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score

# Utilizando uma função que facilita a conferência de diversas métricas
from sklearn.metrics import classification_report

"""# Botões"""

import ipywidgets as widgets
from IPython.display import display

# 1. Define the widget
# RadioButtons requires a list of options.
options_list = ['Sim', 'Não']

radio_button = widgets.RadioButtons(
    options=options_list,
    description='O valor de R2_score é satisfatório?:',
    disabled=False,
    value=None,
    style={'description_width': 'initial'}
)

"""# Avaliação de Modelos Preditivos

## Avaliação para Regressão

Para exemplificar de maneira prática o uso das métricas para regressão, utilizaremos o problema sobre estimativas de preço das casas na [Califórnia](https://www.kaggle.com/datasets/camnugent/california-housing-prices) e avaliaremos o desempenho do modelo treinado com métricas diversas
"""

# @title Carregando os dados

califa_dataset = fetch_california_housing()

# @title Neste parágrafo, mostre os dados do dataset criado no parágrafo anterior

print(califa_dataset.keys())
print(califa_dataset.DESCR)

califa_df = pd.DataFrame(califa_dataset.data, columns=califa_dataset.feature_names)
print(califa_df.head())

# @title Neste parágrafo, separe os atributos preditivos (crie a variável data) do atributo alvo (crie a variável target)

data = califa_dataset.data
target = califa_dataset.target

# @title Neste parágrafo, mostre o conteúdo da variável data

print(data[:5])

# @title Neste parágrafo, mostre o conteúdo da variável target

print(target[:5])

# @title Neste parágrafo, aplique a técnica de hold-out com os seguintes parâmetros: test_size=0.2, random_state=12

X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(data, target, test_size=0.2, random_state=12)

# @title Neste parágrafo, inicialize o classificador DecisionTreeRegressor com o parâmetro: random_state=42

regressor = DecisionTreeRegressor(random_state=42)

# @title Neste parágrafo, treine o modelo

regressor.fit(X_train_reg, y_train_reg)

# @title Neste parágrafo, realize as predições na base de teste

y_pred_reg = regressor.predict(X_test_reg)

# @title Neste parágrafo, imprima o valor de avaliação de desempenho para MSE

mse = mean_squared_error(y_test_reg, y_pred_reg)
print(f"Mean Squared Error (MSE): {mse}")

# @title Neste parágrafo, imprima o valor de avaliação de desempenho para RMSE

rmse = np.sqrt(mse)
print(f"Root Mean Squared Error (RMSE): {rmse}")

# @title Neste parágrafo, imprima o valor de avaliação de desempenho para MAE

mae = mean_absolute_error(y_test_reg, y_pred_reg)
print(f"Mean Absolute Error (MAE): {mae}")

# @title Neste parágrafo, imprima o valor de avaliação de desempenho para R2_score

r2 = r2_score(y_test_reg, y_pred_reg)
print(f"R2 Score: {r2}")

display(radio_button)

# @title Neste parágrafo, justifique a resposta anterior

"""O valor do R2 Score é aproximadamente 0.656 e quanto mais próximo o valor for de 1, indica um melhor ajuste do modelo.
Desse modo, um R2 de 0.656 significa que o modelo explica apenas 65,6% da variabilidade no preço das casas,
considerado um desempenho moderado, pois quase 35% da variação dos dados não está sendo capturada pelo modelo.
Portanto, o ajuste não é satisfatório e o modelo pode ser melhorado."""

"""## Avaliação para Classificação

Para exemplificar a utilização das métricas de avaliação para classificação, vamos estender o exemplo de pacientes com diabetes para ter uma avaliação mais completa, observando o resultado do desempenho a partir de algumas das diversas métricas.

### Montar o Google Drive
"""

drive.mount('/content/drive', force_remount=True)

"""### Ler o arquivo

Utilizaremos o conjunto de dados de [diabetes](https://drive.google.com/file/d/1PXyKtyVGDJ2OPyIMdrqzIysrcleelDXM/view?usp=sharing) para a indução de modelos.
"""

file_path = '/content/drive/MyDrive/Colab Notebooks/diabetes.csv';

df = pd.read_csv(file_path);

# @title Neste parágrafo, mostre o conteúdo do dataset {df}

print(df.head())

print("\nInformações do DataFrame:")
df.info()

print("\nEstatísticas Descritivas:")
print(df.describe())

# @title Neste parágrafo, separe os dados em atributos preditivos (X) e atributo alvo (y)

X = df.drop('Outcome', axis=1)
y = df['Outcome']

# @title Neste parágrafo, mostre o conteúdo da variável (X)

print(X.head())

# @title Neste parágrafo, mostre o conteúdo da variável (y)

print(y.head())

# @title Neste parágrafo, aplique a técnica de hold-out com os seguintes parâmetros (test_size=0.3, random_state=12, stratify=y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12, stratify=y)

# @title Neste parágrafo, inicialize o classificador DecisionTreeClassifier com o seguinte parâmetro: random_state=42

classifier = DecisionTreeClassifier(random_state=42)

# @title Neste parágrafo, treine o modelo

classifier.fit(X_train, y_train)

# @title Neste parágrafo, realize as predições na base de teste

y_pred = classifier.predict(X_test)

# @title Neste parágrafo, mostre os valores de avaliação de desempenho para as seguintes métricas (Acurácia, F1-Score, Revocação (Recall), Precisão e AUC)

y_pred_proba = classifier.predict_proba(X_test)[:, 1]

print(f"Acurácia: {accuracy_score(y_test, y_pred)}")
print(f"F1-Score (ponderado para a classe positiva): {f1_score(y_test, y_pred)}")
print(f"Recall (Revocação) (para a classe positiva): {recall_score(y_test, y_pred)}")
print(f"Precisão (para a classe positiva): {precision_score(y_test, y_pred)}")
print(f"AUC (Area Under Curve): {roc_auc_score(y_test, y_pred_proba)}")

# @title Neste parágrafo, utilize a função {classification_report} e mostra as métricas

report = classification_report(y_test, y_pred, target_names=['Classe 0 (Não Diabético)', 'Classe 1 (Diabético)'])
print(report)