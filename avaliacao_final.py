# -*- coding: utf-8 -*-
"""Aula 140. Avaliação final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fYn4jA7pdSmkdx5v5NzyezZLpJ9sLF9S

# Avaliação final

Este notebook abordará conceitos sobre metodologia experimental e análise de desempenho de métodos de aprendizado de máquina. Para isso, empregaremos o método do K-vizinhos mais próximos (*K-nearest neighbors* - KNN) [1], com medidas de acurácia, precisão, revocação e F-medida.

<br>

Os experimentos serão realizados com a base de dados Iris [2]. Essa base de dados pode ser encontrada no seguinte [hiperlink](https://drive.google.com/file/d/1ZrRe2fkGhzwaH4rIy7o3X3X-TCzpHDJQ/view?usp=drive_link).

<br>

A flor Iris é composta por três espécies: **Setosa**, **Virginica** e **Versicolour**. A base de dados usada neste trabalho é formada por quatro atributos: comprimento e largura das pétalas e comprimento e largura das sépalas.   

<br>

Ao final deste notebook, é esperado que o leitor tenha assimilado as principais etapas necessárias para fazer a classificação dos dados e analisar adequadamente os resultados.

# Pontuação da Avaliação final

Esta avaliação final possui 20 parágrafos que deverão ser preenchidos com a instrução correta.

Cada parágrafo preenchido corretamente valerá 0,5 ponto.

A pontuação final pode alcançar 10 pontos.

## Atenção: As instruções devem ser inseridas no parágrafo definido na avaliação.
### Instruções em locais incorretos não serão consideradas.
### Não remova o título do parágrafo. Exemplo: (1 de 20) Neste parágrafo, ...
### Não remova os parágrafos da avaliação.

---
# Recursos Necessários

Para este *notebook*, deve ser utilizado o `Python 3.5` ou superior com as seguintes bibliotecas externas, que deverão ser instaladas:
* [`matplotlib`](https://matplotlib.org/3.1.1/index.html) (versão 3.1.3 ou superior): construção e exibição de gráficos variados
* [`seaborn`](https://seaborn.pydata.org/) (versão 0.10.0 ou superior): construção e exibição de gráficos variados
* [`numpy`](https://numpy.org) (versão 1.16.2 ou superior): manipulação de dados em formato de vetores e matrizes
* [`pandas`](https://pandas.pydata.org/pandas-docs/stable/index.html) (versão 0.24.1 ou superior): manipulação de dados em formato de tabelas
* [`scikit-learn`](https://scikit-learn.org/stable/)  (versão 0.22.1 ou superior): conjunto de métodos e modelos úteis para Aprendizado de Máquina e Inteligência Artificial

# Importação de bibliotecas
"""

# @title (1 de 20) Neste parágrafo, importe as bibliotecas necessárias

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
from sklearn import metrics
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from google.colab import drive

"""# Funções

## Superfície de decisão

A função abaixo imprime uma figura com a superfície de decisão das classes
"""

#def plota_superficieDecisao(classifier, X, Y, ax, title = ""):
def plota_superficieDecisao(classifier, X, Y, title = ""):

    fig, ax = plt.subplots(figsize=(8, 8))

    h = .02  # tamanho do passo da malha (mesh)

    # cria uma malha (mesh)
    x_min, x_max = X[:, 0].min() - 0.3, X[:, 0].max() + 0.3
    y_min, y_max = X[:, 1].min() - 0.3, X[:, 1].max() + 0.3
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))


    # obtem a predicao
    Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])

    # converte os valores do vetor para indices
    Z2 = np.unique(Z, return_inverse=True)[1]

    # plota a superficie de decisao
    Z2 = Z2.reshape(xx.shape)
    ax.contourf(xx, yy, Z2, cmap=plt.cm.Paired, alpha=.4)

    # converte os valores do vetor para indices
    Y2 = np.unique(Y, return_inverse=True)[1]

    # plota os dados de treinamento
    ax.scatter(X[:, 0], X[:, 1], c=Y2, edgecolor='k', s=50)

    ax.set_xlim(xx.min(), xx.max())
    ax.set_ylim(yy.min(), yy.max())
    ax.set_title(title, fontsize='large')

"""## Relatório de desempenho

Na função abaixo, será gerado um relatório com as principais medidas de desempenho. Será calculada a **precisão**, **revocação** e **F-medida** para cada uma das classes do problema. Adicionalmente, será calculada a **acurácia**, **macro** e **micro precisão**, **macro** e **micro revocação** e, por fim, a **macro** e **micro F-medida**.
"""

def relatorioDesempenho(Y_test, Y_pred, classes, imprimeRelatorio=True):
  """
  Funcao usada calcular as medidas de desempenho da classificação.

  Parametros
  ----------

  classes: classes do problema

  imprimeRelatorio: variavel booleana que indica se o relatorio de desempenho
                    deve ser impresso ou nao.

  Retorno
  -------
  resultados: variavel do tipo dicionario (dictionary). As chaves
              desse dicionario serao os nomes das medidas de desempenho; os valores
              para cada chave serao as medidas de desempenho calculadas na funcao.

              Mais especificamente, o dicionario devera conter as seguintes chaves:

               - acuracia: valor entre 0 e 1
               - revocacao: um vetor contendo a revocacao obtida em relacao a cada classe
                            do problema
               - precisao: um vetor contendo a precisao obtida em relacao a cada classe
                            do problema
               - fmedida: um vetor contendo a F-medida obtida em relacao a cada classe
                            do problema
               - revocacao_macroAverage: valor entre 0 e 1
               - precisao_macroAverage: valor entre 0 e 1
               - fmedida_macroAverage: valor entre 0 e 1
               - revocacao_microAverage: valor entre 0 e 1
               - precisao_microAverage: valor entre 0 e 1
               - fmedida_microAverage: valor entre 0 e 1
  """

  # obtem a quantidade de classes
  nClasses = len(classes)

  # obtem a acuracia
  acuracia = metrics.accuracy_score(Y_test, Y_pred)

  # inicializa as medidas de desempenho
  revocacao = np.zeros( len(classes) )
  precisao = np.zeros( len(classes) )
  fmedida = np.zeros( len(classes) )

  # calcula a medida de desempenho para cada classe individualmente
  for i in range( len(classes) ):

      # transforma o problema multiclasse em binário, apenas para calcular o desempenho individual da classe i
      auxY_test = np.zeros( len(Y_test) ) # inicializa o vetor de classes binárias com 0
      auxY_pred = np.zeros( len(Y_pred) ) # inicializa o vetor de classes binárias com 0
      auxY_test[Y_test==classes[i]] = 1 # onde a classe for igual a classe[i], recebe valor 1
      auxY_pred[Y_pred==classes[i]] = 1 # onde a classe for igual a classe[i], recebe valor 1

      revocacao[i] = metrics.recall_score(auxY_test, auxY_pred, pos_label=1) # revocacao
      precisao[i] = metrics.precision_score(auxY_test, auxY_pred, pos_label=1) # precisao
      fmedida[i] = metrics.f1_score(auxY_test, auxY_pred, pos_label=1) # f-medida


  revocacao_microAverage =  metrics.recall_score(Y_test, Y_pred, average='micro')
  precisao_microAverage = metrics.precision_score(Y_test, Y_pred, average='micro')
  fmedida_microAverage = metrics.f1_score(Y_test, Y_pred, average='micro')

  revocacao_macroAverage =  metrics.recall_score(Y_test, Y_pred, average='macro')
  precisao_macroAverage = metrics.precision_score(Y_test, Y_pred, average='macro')
  fmedida_macroAverage = metrics.f1_score(Y_test, Y_pred, average='macro')


  # imprime os resultados para cada classe
  if imprimeRelatorio:

      print('\n\tRevocacao   Precisao   F-medida   Classe')
      for i in range(nClasses):
        print('\t%1.3f       %1.3f      %1.3f      %s' % (revocacao[i], precisao[i], fmedida[i],classes[i] ) )

      print('\t------------------------------------------------');

      #imprime as médias
      print('\t%1.3f       %1.3f      %1.3f      Média macro' % (revocacao_macroAverage, precisao_macroAverage, fmedida_macroAverage) )
      print('\t%1.3f       %1.3f      %1.3f      Média micro\n' % (revocacao_microAverage, precisao_microAverage, fmedida_microAverage) )

      print('\tAcuracia: %1.3f' %acuracia)

  # armazena os resultados em uma estrutura tipo dicionario
  resultados = {'revocacao': revocacao, 'acuracia': acuracia, 'precisao':precisao, 'fmedida':fmedida}
  resultados.update({'revocacao_macroAverage':revocacao_macroAverage, 'precisao_macroAverage':precisao_macroAverage, 'fmedida_macroAverage':fmedida_macroAverage})
  resultados.update({'revocacao_microAverage':revocacao_microAverage, 'precisao_microAverage':precisao_microAverage, 'fmedida_microAverage':fmedida_microAverage})

  return resultados

"""# Montar o Google Drive"""

# @title (2 de 20) Neste parágrafo, monte o Google drive

drive.mount('/content/drive', force_remount=True)

# @title (3 de 20) Neste parágrafo, definia o diretório e leia o arquivo utilizado para a avaliação

file_path = '/content/drive/MyDrive/Colab Notebooks/iris.csv'

df = pd.read_csv(file_path);

"""---
# Validação Holdout

Vamos analisar a classificação usando a validação *holdout* estratificada.
"""

# @title (4 de 20) Neste parágrafo, exiba 10 linhas iniciais do dataframe

df.head(10)

"""Por questões didáticas, vamos realizar os experimentos considerando apenas os atributos largura (*SepalWidthCm*) e comprimento da sépala (*SepalLengthCm*)."""

# @title (5 de 20) Neste parágrafo, remova as colunas que não serão usadas

df = df.drop(['Id', 'PetalLengthCm', 'PetalWidthCm'], axis=1)

# @title (6 de 20) Neste parágrafo, exiba as 10 primeiras linhas do dataframe resultante

df.head(10)

"""Vamos plotar os dados."""

# @title (7 de 20) Neste parágrafo, crie o gráfico scatter plot dos dados: SepalLength X SepalWidthCm

plt.figure(figsize=(8, 6))
sns.scatterplot(data=df, x='SepalLengthCm', y='SepalWidthCm', hue='Species')
plt.show()

"""Armazene os dados dentro de uma matriz e as classes dentro de um vetor. As cinco primeiras linhas da matriz de dados e do vetor de classes serão exibidos."""

# @title (8 de 20) Neste parágrafo, armazene os dados (atributos preditivos) em uma matriz X e as classes (variável dependente) em um vetor Y.

X = df.drop('Species', axis=1).values
Y = df['Species'].values

# @title (9 de 20) Neste parágrafo, exiba as 5 primeiras linhas da matriz X

print(X[:5])

# @title (10 de 20) Neste parágrafo, exiba as 5 primeiras linhas do vetor Y.

print(Y[:5])

"""A validação *holdout* estratificada consiste em dividir a base de dados em duas partições (treino e teste), mantendo a distribuição original de dados de cada classe em cada partição. Os primeiros $p\%$ dos dados de cada classe devem compor o conjunto de treinamento, enquanto o restante deve compor os dados de teste. Para isso, usaremos a função `sklearn.model_selection.StratifiedShuffleSplit`.

A função `sklearn.model_selection.StratifiedShuffleSplit` pode ser usada para gerar $n$ particionamentos estratificados. A quantidade de particionamentos é definida pelo parâmetro `n_splits`.  Na validação *holdout*, usamos apenas um particionamento de treino e de teste. Por isso, iremos setar o parâmetro `n_splits` com valor 1.

É importante que as partições de treinamento e teste sejam geradas de forma aleatória. Para que toda a execução gere o mesmo resultado, vamos usar uma semente para a função de geração de números aleatórios, setando um valor para o parâmetro `random_state`.
"""

# @title (11 de 20) Neste parágrafo, gere uma divisão holdout estratificada dos dados em treino e teste, com 70% de dados para o treinamento e 30% para teste com StratifiedShuffleSplit. O parâmetro random_state deve ser igual a 2020.

sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=2020)

for train_index, test_index in sss.split(X, Y):
    X_train, X_test = X[train_index], X[test_index]
    Y_train, Y_test = Y[train_index], Y[test_index]

# @title (12 de 20) Neste parágrafo, imprima a quantidade de dados de treinamento e teste

print(f"Treinamento: {X_train.shape[0]} amostras")
print(f"Teste: {X_test.shape[0]} amostras")

# @title (13 de 20) Neste parágrafo, imprima a porcentagem de dados de treinamento de cada classe

pd.Series(Y_train).value_counts(normalize=True)

# @title (14 de 20) Neste parágrafo, imprima a porcetagem de dados de teste de cada classe

pd.Series(Y_test).value_counts(normalize=True)

"""Alguns métodos de aprendizado de máquina são sensíveis à escala dos valores dos atributos. Portanto, vamos normalizar os valores dos atributos para que fiquem com média igual a zero e desvio padrão igual a um."""

# @title (15 de 20) Neste parágrafo, normalize os valores dos atributos (treino e teste) para que fiquem com media igual a zero e desvio padrao igual a um

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""Agora que separamos os dados em duas partições, podemos treinar um método de classicação na partição de treinamento e testar na partição de teste. Para isso, vamos usar o algoritmo **KNN** (Método Baseado em Distâncias)."""

# @title (16 de 20) Neste parágrafo, treine o classificador KNeighborsClassifier com 5 vizinhos

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, Y_train)

# @title (17 de 20) Neste prágrafo, realize a predição utilizando os dados de teste. Imprima as 20 primeiras predições.

Y_pred = knn.predict(X_test)
print(Y_pred[:20])

"""Vamos dar uma olhada na superfície de decisão aprendida pelo KNN."""

# @title (18 de 20) Neste parágrafo, imprima a superfície de decisão utilizando a função plota_superficieDecisao disponível na seção Funções

plota_superficieDecisao(knn, X_test, Y_test, title="Superfície de Decisão - KNN (k=5)")
plt.show()

"""### Matriz de confusão

Agora que treinamos o método de classificação, precisamos avaliar o seu desempenho. A maioria das medidas de desempenho pode ser calculada a partir da matriz de confusão. A Tabela 1 apresenta um exemplo de matriz de confusão para um problema com duas classes: **pos** e **neg**.

 <table style="text-align:center">
  <tr>
    <th> </th>
    <th>Predição = pos</th>
    <th>Predição = neg</th>
  </tr>
  <tr>
    <td><b>Classe = pos</b></td>
    <td>vp</td>
    <td>fn</td>
  </tr>
  <tr>
      <td><b>Classe = neg</b></td>
    <td>fp</td>
    <td>vn</td>
  </tr>
</table>
<br/>
<center><em>Tabela 1. Exemplo de matriz de confusão para um problema binário.</em></center>
<br/>

A partir da matriz de confusão mostrada acima, podemos coletar os seguintes valores:

* **verdadeiros positivos (vp)**: quantidade de exemplos corretamente classificados como pertencentes à classe positiva.
* **falsos positivos (fp)**: quantidade de exemplos incorretamente classificados como pertencentes à classe positiva.
* **verdadeiros negativos (vn)**: quantidade de exemplos corretamente classificados como pertencentes à classe negativa.
* **falsos negativos (fn)**: quantidade de exemplos incorretamente classificados como pertencentes à classe negativa.

A matriz de confusão apresentada na Tabela 1 pode ser facilmente estendida para problemas multiclasse. Para um problema de $|C|$ classes, a matriz de confusão terá dimensão $|C|\times|C|$ e pode ser representada conforme mostra a Tabela 2.

 <table>
  <tr style="text-align:center">
    <th> </th>
    <th style="text-align:center">Predição = $c_1$</th>
    <th style="text-align:center">Predição = $c_2$</th>
    <th style="text-align:center">$\dots$</th>
    <th style="text-align:center">Predição = $c_{|C|}$</th>
  </tr>
  <tr style="text-align:center">
    <td style="text-align:center"><b>Classe = $c_1$</b></td>
    <td style="text-align:center">$k_{11}$</td>
    <td style="text-align:center">$k_{12}$</td>
    <td style="text-align:center">$\dots$</td>
    <td style="text-align:center">$k_{1|C|}$</td>
  </tr>
  <tr style="text-align:center">
    <td style="text-align:center"><b>Classe = $c_2$</b></td>
    <td style="text-align:center">$k_{21}$</td>
    <td style="text-align:center">$k_{22}$</td>
    <td style="text-align:center">$\dots$</td>
    <td style="text-align:center">$k_{2|C|}$</td>
  </tr>
  <tr style="text-align:center">
    <td style="text-align:center"><b>$\vdots$</b></td>
    <td style="text-align:center">$\vdots$</td>
    <td style="text-align:center">$\vdots$</td>
    <td style="text-align:center">$\ddots$</td>
    <td style="text-align:center">$\vdots$</td>
  </tr>
  <tr style="text-align:center">
    <td style="text-align:center"><b>Classe = $c_{|C|}$</b></td>
    <td style="text-align:center">$k_{|C|1}$</td>
    <td style="text-align:center">$k_{|C|2}$</td>
    <th style="text-align:center">$\dots$</th>
    <td style="text-align:center">$k_{|C||C|}$</td>
  </tr>
</table>
<br/>
<center><em>Tabela 2. Exemplo de matriz de confusão para um problema multiclasse.</em></center>

A quantidade de **vp**, **vn**, **fp** e **fn** em relação a uma classe $c_j$, usando os valores apresentados na matriz de confusão (Tabela 2), pode ser calculada da seguinte forma:

* $\text{vp}_j=k_{jj}$: quantidade de exemplos corretamente classificados como pertencentes à classe $c_j$;

* $\text{fp}_j=\sum_{p=1|p\neq j}^{{|\mathcal{C}|}} k_{pj}$: quantidade de exemplos incorretamente classificados como pertencentes à classe $c_j$;

* $\text{vn}_j=\sum_{i=1|i\neq j}^{{|\mathcal{C}|}} \sum_{p=1|p\neq j}^{{|\mathcal{C}|}} k_{pi}$: quantidade de exemplos corretamente classificados como não pertencentes à classe $c_j$;

* $\text{fn}_j=\sum_{p=1|p\neq j}^{{|\mathcal{C}|}} k_{jp}$: quantidade de exemplos da classe $c_j$ incorretamente classificados como pertencentes a outra classe.

Outra maneira de calcular **vp**, **vn**, **fp** e **fn** para uma classe $c_j$ em um problema multiclasse é gerar uma matriz de confusão binária onde $c_j$ é considerada a classe positiva e todas as outras são consideradas uma única classe negativa.

Usando a biblioteca `scikit-learn`, podemos obter a matriz de confusão usando a função `sklearn.metrics.confusion_matrix`.
"""

# @title (19 de 20) Neste parágrafo, imprima a matriz de confusão e os valores para o problema multiclasse apresentado na avaliação usando um gráfico HeatMap

matriz_confusao = metrics.confusion_matrix(Y_test, Y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(matriz_confusao, annot=True, fmt='d', cmap='Blues',
            xticklabels=knn.classes_, yticklabels=knn.classes_)
plt.xlabel('Predição')
plt.ylabel('Real')
plt.title('Matriz de Confusão')
plt.show()

"""### Medidas de desempenho

Vamos calcular o desempenho do algoritmo de classificação. Algumas medidas de desempenho (*e.g.*, acurácia) retornam um valor global de desempenho, enquanto que outras (*e.g.*, precisão, revocação e F-medida) retornam um valor que pode variar dependendo de qual classe é considerada como positiva (classe alvo do problema). Supondo que em um determinado problema, a classe $c_1$ seja considerada a classe positiva, as seguintes medidas de desempenho podem ser calculadas:

* $\displaystyle \text{acurácia} =\frac{vp_1+vn_1}{vp_1+vn_1+fp_1+fn_1} = \frac{\text{Qtd. de predições corretas}}{\text{Qtd. de amostras}};$

* $\displaystyle \text{revocação} =  \frac{vp_1}{vp_1+fn_1} \text{;} $

* $\displaystyle \text{precisão} = \frac{vp_1}{vp_1+fp_1}; $

* $\displaystyle \text{F-medida} = 2 \times \frac{\text{precisão} \times\text{revocação}}{\text{precisão}+\text{revocação}}.$

Para problemas binários sem uma classe-alvo ou para problemas multiclasse, normalmente são utilizadas medidas de desempenho que consideram a média entre os resultados relativos a cada classe do problema. As duas principais estratégias para obter a média de desempenho entre as classes são a média macro e a média micro. A média macro considera que todas as classes possuem a mesma importância. Por outro lado, na média micro, o resultado final é dominado pelas classes mais frequentes, o que pode gerar um desempenho superestimado quando as classes são muito desbalanceadas. Abaixo, são apresentadas algumas medidas de desempenho calculadas por meio dessas duas estratégias.

* Medidas baseadas na média macro:
 - $ \displaystyle \text{macro revocação} = \frac{1}{{|\mathcal{C}|}} \times \sum_{j=1}^{{|\mathcal{C}|}} \frac{vp_j}{vp_j+fn_j}$;

 - $ \displaystyle \text{macro precisão} = \frac{1}{{|\mathcal{C}|}} \times \sum_{j=1}^{{|\mathcal{C}|}} \frac{vp_j}{vp_j+fp_j}$;

 - $ \displaystyle \text{macro F-medida} = 2 \times \frac{\text{macro precisão} \times\text{macro revocação}}{\text{macro precisão}+\text{macro revocação}}$.


* Medidas baseadas na média micro:
 - $ \displaystyle \text{micro revocação} = \frac{\sum_{j=1}^{{|\mathcal{C}|}} vp_j}{\sum_{j=1}^{{|\mathcal{C}|}} vp_j+fn_j}$;

 - $ \displaystyle \text{micro precisão} = \frac{\sum_{j=1}^{{|\mathcal{C}|}} vp_j}{\sum_{j=1}^{{|\mathcal{C}|}} vp_j+fp_j}$;

 - $ \displaystyle \text{micro F-medida} = 2 \times \frac{\text{micro precisão} \times\text{micro revocação}}{\text{micro precisão}+\text{micro revocação}}$.


"""

# @title (20 de 20) Neste parágrafo, imprima o Relatório de desempenho por meio da função relatorioDesempenho() disponível na seção Funções

relatorioDesempenho(Y_test, Y_pred, knn.classes_)

"""---
# Referências

[1] T. Cover, P. Hart, Nearest neighbor pattern classification, IEEE Trans. Inf. Theory
13 (1) (1967) 21–27. DOI: [10.1109/TIT.1967.1053964](http://dx.doi.org/10.1109/TIT.1967.1053964).

[2] R. A. Fisher. The use of multiple measurements in taxonomic problems. Annual Eugenics, 7, Part II, 179-188 (1936). DOI: [10.1111/j.1469-1809.1936.tb02137.x](http://dx.doi.org/10.1111/j.1469-1809.1936.tb02137.x).

[3] V. Metsis, I. Androutsopoulos, G. Paliouras (2006). Spam filtering with naive Bayes – which naive Bayes? In Proceedings of the 3rd Conference on Email and Anti-Spam (CEAS’06), pages 27–28, Mountain View, California.

[4] C. Cortes, V. Vapnik, Support-vector networks, Machine Learning 20 (3) (1995) 273–297. DOI: [10.1007/BF00994018](http://dx.doi.org/10.1007/BF00994018).

[5] L. Breiman, J. Friedman, C. J. Stone, R. A. Olshen, Classification and Regression Trees, CRC Press, Boca Raton, FL, USA, 1984.

[6] H.-F. Yu, F.-L. Huang, C.-J. Lin (2011). Dual coordinate descent methods for logistic regression and maximum entropy models. Machine Learning, 85(1-2):41–75. DOI: [10.1007/s10994-010-5221-8](http://dx.doi.org/10.1007/s10994-010-5221-8).

---
"""